{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from IPython.core.display import display\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "from utils_torch import *\n",
    "from datasets.flickr8k import Flickr8kDataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DATASET_BASE_PATH = 'data/flickr8k/'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_set = Flickr8kDataset(dataset_base_path=DATASET_BASE_PATH, dist='train', device=device)\n",
    "vocab, word2idx, idx2word, max_len = vocab_set = train_set.get_vocab()\n",
    "val_set = Flickr8kDataset(dataset_base_path=DATASET_BASE_PATH, dist='val', vocab_set=vocab_set, device=device)\n",
    "test_set = Flickr8kDataset(dataset_base_path=DATASET_BASE_PATH, dist='test', vocab_set=vocab_set, device=device)\n",
    "len(train_set), len(val_set), len(test_set)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "vocab_size, max_len"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "samples_per_epoch = len(train_set)\n",
    "samples_per_epoch\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_model(model, train_generator, steps_per_epoch, optimizer, loss_fn, wandb_log=False):\n",
    "    running_acc = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    t = trange(steps_per_epoch, leave=True)\n",
    "    for batch_idx in t:  # enumerate(iter(steps_per_epoch)):\n",
    "        batch = next(train_generator)\n",
    "        (enc, cap_in, next_word) = batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(enc, cap_in)\n",
    "        loss = loss_fn(output, next_word)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_acc += (torch.argmax(output, dim=1) == next_word).sum().item() / next_word.size(0)\n",
    "        running_loss += loss.item()\n",
    "        t.set_postfix({'loss': running_loss / (batch_idx + 1),\n",
    "                       'acc': running_acc / (batch_idx + 1)}, refresh=True)\n",
    "\n",
    "    return model, running_loss\n",
    "\n",
    "\n",
    "def train_model_new(train_loader, encoder, decoder, loss_fn, optimizer, vocab_size):\n",
    "    running_acc = 0.0\n",
    "    running_loss = 0.0\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    t = tqdm(iter(train_loader))\n",
    "    for batch_idx, batch in enumerate(t):  # enumerate(iter(steps_per_epoch)):\n",
    "        images, captions = batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        features = encoder(images)\n",
    "        outputs = decoder(features, captions)\n",
    "\n",
    "        loss = loss_fn(outputs.view(-1, vocab_size), captions.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_acc += (torch.argmax(outputs.view(-1, vocab_size), dim=1) == captions.view(\n",
    "            -1)).sum().item() / captions.view(-1).size(0)\n",
    "        running_loss += loss.item()\n",
    "        t.set_postfix({'loss': running_loss / (batch_idx + 1),\n",
    "                       'acc': running_acc / (batch_idx + 1),\n",
    "                       }, refresh=True)\n",
    "\n",
    "    return running_loss / len(train_loader)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MODEL = \"resnet50_monolstm\"\n",
    "EMBEDDING_DIM = 50\n",
    "EMBEDDING = f\"GLV{EMBEDDING_DIM}\"\n",
    "BATCH_SIZE = 16\n",
    "LR = 1e-2\n",
    "MODEL_NAME = f'saved_models/{MODEL}_b{BATCH_SIZE}_emd{EMBEDDING}'\n",
    "NUM_EPOCHS = 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from models.torch.resnet50_monolstm import Encoder\n",
    "\n",
    "encoder = Encoder(embed_size=300).to(device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from models.torch.resnet50_monolstm import Decoder\n",
    "\n",
    "encoder = Encoder(embed_size=EMBEDDING_DIM).to(device)\n",
    "decoder = Decoder(EMBEDDING_DIM, 256, vocab_size, num_layers=2).to(device)\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = torch.nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Specify the learnable parameters of the model\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters()) + list(encoder.bn.parameters())\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(params=params, lr=LR)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_set.transformations = transforms.Compose([\n",
    "    transforms.Resize(256),  # smaller edge of image resized to 256\n",
    "    transforms.RandomCrop(224),  # get 224x224 crop from random location\n",
    "    # transforms.RandomHorizontalFlip(),               # horizontally flip image with probability=0.5\n",
    "    transforms.ToTensor(),  # convert the PIL Image to a tensor\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),  # normalize image for pre-trained model\n",
    "                         (0.229, 0.224, 0.225))\n",
    "])\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=False, sampler=None)\n",
    "train_loss_min = 100\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{NUM_EPOCHS}', flush=True)\n",
    "    train_loss = train_model_new(encoder=encoder, decoder=decoder, optimizer=optimizer, loss_fn=loss_fn,\n",
    "                                 train_loader=train_loader, vocab_size=vocab_size)\n",
    "#     state = {\n",
    "#         'epoch': epoch + 1,\n",
    "#         'state_dict': final_model.state_dict(),\n",
    "#         'optimizer': optimizer.state_dict()\n",
    "#     }\n",
    "#     if (epoch + 1) % 2 == 0:\n",
    "#         torch.save(state, f'{MODEL_NAME}_ep{epoch:02d}_weights.pt')\n",
    "#     if train_loss < train_loss_min:\n",
    "#         train_loss_min = train_loss\n",
    "#         torch.save(state, f'{MODEL_NAME}''_best_train.pt')\n",
    "# torch.save(final_model, f'{MODEL_NAME}_ep{5:02d}_weights.pt')\n",
    "# final_model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = torch.load(f'{MODEL_NAME}''_best_train.pt')\n",
    "model = final_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try_image = train_set.imgpath_list[100]\n",
    "display(Image.open(try_image))\n",
    "print('Normal Max search:', greedy_predictions_gen(encoding_dict=encoding_train, model=model,\n",
    "                                                   word2idx=word2idx, idx2word=idx2word,\n",
    "                                                   images=train_set.images_path, max_len=max_len, device=device)(\n",
    "    try_image))\n",
    "for k in [3, 5, 7]:\n",
    "    print(f'Beam Search, k={k}:',\n",
    "          beam_search_predictions_gen(beam_index=k, encoding_dict=encoding_train, model=model,\n",
    "                                      word2idx=word2idx, idx2word=idx2word,\n",
    "                                      images=train_set.images_path, max_len=max_len, device=device)(try_image))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try_image = val_set.imgpath_list[4]\n",
    "display(Image.open(try_image))\n",
    "print('Normal Max search:', greedy_predictions_gen(encoding_dict=encoding_valid, model=model,\n",
    "                                                   word2idx=word2idx, idx2word=idx2word,\n",
    "                                                   images=train_set.images_path, max_len=max_len)(try_image))\n",
    "for k in [3, 5, 7]:\n",
    "    print(f'Beam Search, k={k}:',\n",
    "          beam_search_predictions_gen(beam_index=k, encoding_dict=encoding_valid, model=model,\n",
    "                                      word2idx=word2idx, idx2word=idx2word,\n",
    "                                      images=train_set.images_path, max_len=max_len)(try_image))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try_image = test_set.imgpath_list[4]\n",
    "display(Image.open(try_image))\n",
    "print('Normal Max search:', greedy_predictions_gen(encoding_dict=encoding_test, model=model,\n",
    "                                                   word2idx=word2idx, idx2word=idx2word,\n",
    "                                                   images=train_set.images_path, max_len=max_len)(try_image))\n",
    "for k in [3, 5, 7]:\n",
    "    print(f'Beam Search, k={k}:',\n",
    "          beam_search_predictions_gen(beam_index=k, encoding_dict=encoding_test, model=model,\n",
    "                                      word2idx=word2idx, idx2word=idx2word,\n",
    "                                      images=train_set.images_path, max_len=max_len)(try_image))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"BLEU Scores:\")\n",
    "print(\"\\tTrain\")\n",
    "print_eval_metrics(img_cap_dict=train_d, encoding_dict=encoding_train, model=model,\n",
    "                   word2idx=word2idx, idx2word=idx2word,\n",
    "                   images=train_set.images_path, max_len=max_len)\n",
    "print(\"\\tValidation\")\n",
    "print_eval_metrics(img_cap_dict=val_d, encoding_dict=encoding_valid, model=model,\n",
    "                   word2idx=word2idx, idx2word=idx2word,\n",
    "                   images=train_set.images_path, max_len=max_len)\n",
    "print(\"\\tTest\")\n",
    "print_eval_metrics(img_cap_dict=test_d, encoding_dict=encoding_test, model=model,\n",
    "                   word2idx=word2idx, idx2word=idx2word,\n",
    "                   images=train_set.images_path, max_len=max_len)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}