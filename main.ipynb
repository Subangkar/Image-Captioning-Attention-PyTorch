{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from IPython.core.display import display\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "from utils_torch import *\n",
    "from datasets.flickr8k import Flickr8kDataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DATASET_BASE_PATH = 'data/flickr8k/'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dset = Flickr8kDataset(dataset_base_path=DATASET_BASE_PATH)\n",
    "\n",
    "train_img = dset.get_imgpath_list(dist='train')\n",
    "val_img = dset.get_imgpath_list(dist='val')\n",
    "test_img = dset.get_imgpath_list(dist='test')\n",
    "len(train_img), len(val_img), len(test_img)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_d = dset.get_imgpath_to_caplist_dict(img_path_list=train_img)\n",
    "val_d = dset.get_imgpath_to_caplist_dict(img_path_list=val_img)\n",
    "test_d = dset.get_imgpath_to_caplist_dict(img_path_list=test_img)\n",
    "len(train_d), len(val_d), len(test_d)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "caps = dset.add_start_end_seq(train_d)\n",
    "vocab, word2idx, idx2word, max_len = dset.construct_vocab(caps=caps)\n",
    "vocab_size = len(vocab)\n",
    "vocab_size, max_len"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "samples_per_epoch = sum(map(lambda cap: len(cap.split()) - 1, caps))\n",
    "samples_per_epoch\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm, trange\n",
    "def train_model(model, train_generator, steps_per_epoch, optimizer, loss_fn, wandb_log=False):\n",
    "    running_acc = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    t = trange(steps_per_epoch, leave=True)\n",
    "    for batch_idx in t:  # enumerate(iter(steps_per_epoch)):\n",
    "        batch = next(train_generator)\n",
    "        (enc, cap_in, next_word) = batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(enc, cap_in)\n",
    "        loss = loss_fn(output, next_word)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # running_acc += torch.mean(output == next_word)\n",
    "        running_loss += loss.item()\n",
    "        t.set_postfix({'loss': running_loss / (batch_idx + 1)}, refresh=True)\n",
    "\n",
    "    return model, running_loss\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from models.torch.resnet50_bidirlstm import Encoder\n",
    "\n",
    "encoder = Encoder().to(device=device)\n",
    "encoding_train = encoder.encode(dset.images, train_img, device=device)\n",
    "encoding_valid = encoder.encode(dset.images, val_img, device=device)\n",
    "encoding_test = encoder.encode(dset.images, test_img, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "MODEL_NAME = f'saved_models/resnet50_bidirlstm_emd200_b{BATCH_SIZE}'\n",
    "steps_per_epoch = int(math.ceil(samples_per_epoch / BATCH_SIZE))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from models.torch.resnet50_bidirlstm import Decoder\n",
    "\n",
    "final_model = Decoder(embedding_size=200, vocab_size=vocab_size, max_len=max_len).to(device=device)\n",
    "optimizer = torch.optim.Adam(final_model.parameters(), lr=1E-3)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_generator = dset.get_generator(batch_size=BATCH_SIZE, random_state=None, device=device,\n",
    "                                     encoding_train=encoding_train, imgpath_to_caplist_dict=train_d,\n",
    "                                     word2idx=word2idx, max_len=max_len)\n",
    "train_loss_min = 100\n",
    "for epoch in range(5):\n",
    "    print(f'Epoch {epoch:02d}/{5:d}')\n",
    "    final_model.train()\n",
    "    final_model, train_loss = train_model(model=final_model, optimizer=optimizer, loss_fn=loss_fn,\n",
    "                                          train_generator=train_generator, steps_per_epoch=steps_per_epoch)\n",
    "    state = {\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': final_model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict()\n",
    "    }\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        torch.save(state, f'{MODEL_NAME}''_ep{epoch:02d}_weights.pt')\n",
    "    if train_loss < train_loss_min:\n",
    "        train_loss_min = train_loss\n",
    "        torch.save(state, f'{MODEL_NAME}''_best_train.pt')\n",
    "torch.save(final_model, f'{MODEL_NAME}''_ep{05}_weights.pt')\n",
    "final_model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model = torch.load(f'{MODEL_NAME}''_best_train.pt')\n",
    "model = final_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try_image = train_img[100]\n",
    "display(Image.open(try_image))\n",
    "print('Normal Max search:', greedy_predictions_gen(encoding_dict=encoding_train, model=model,\n",
    "                                                   word2idx=word2idx, idx2word=idx2word,\n",
    "                                                   images=dset.images, max_len=max_len)(try_image))\n",
    "for k in [3, 5, 7]:\n",
    "    print(f'Beam Search, k={k}:',\n",
    "          beam_search_predictions_gen(beam_index=k, encoding_dict=encoding_train, model=model,\n",
    "                                      word2idx=word2idx, idx2word=idx2word,\n",
    "                                      images=dset.images, max_len=max_len)(try_image))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try_image = val_img[4]\n",
    "display(Image.open(try_image))\n",
    "print('Normal Max search:', greedy_predictions_gen(encoding_dict=encoding_valid, model=model,\n",
    "                                                   word2idx=word2idx, idx2word=idx2word,\n",
    "                                                   images=dset.images, max_len=max_len)(try_image))\n",
    "for k in [3, 5, 7]:\n",
    "    print(f'Beam Search, k={k}:',\n",
    "          beam_search_predictions_gen(beam_index=k, encoding_dict=encoding_valid, model=model,\n",
    "                                      word2idx=word2idx, idx2word=idx2word,\n",
    "                                      images=dset.images, max_len=max_len)(try_image))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try_image = test_img[4]\n",
    "display(Image.open(try_image))\n",
    "print('Normal Max search:', greedy_predictions_gen(encoding_dict=encoding_test, model=model,\n",
    "                                                   word2idx=word2idx, idx2word=idx2word,\n",
    "                                                   images=dset.images, max_len=max_len)(try_image))\n",
    "for k in [3, 5, 7]:\n",
    "    print(f'Beam Search, k={k}:',\n",
    "          beam_search_predictions_gen(beam_index=k, encoding_dict=encoding_test, model=model,\n",
    "                                      word2idx=word2idx, idx2word=idx2word,\n",
    "                                      images=dset.images, max_len=max_len)(try_image))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"BLEU Scores:\")\n",
    "print(\"\\tTrain\")\n",
    "print_eval_metrics(img_cap_dict=train_d, encoding_dict=encoding_train, model=model,\n",
    "                   word2idx=word2idx, idx2word=idx2word,\n",
    "                   images=dset.images, max_len=max_len)\n",
    "print(\"\\tValidation\")\n",
    "print_eval_metrics(img_cap_dict=val_d, encoding_dict=encoding_valid, model=model,\n",
    "                   word2idx=word2idx, idx2word=idx2word,\n",
    "                   images=dset.images, max_len=max_len)\n",
    "print(\"\\tTest\")\n",
    "print_eval_metrics(img_cap_dict=test_d, encoding_dict=encoding_test, model=model,\n",
    "                   word2idx=word2idx, idx2word=idx2word,\n",
    "                   images=dset.images, max_len=max_len)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}